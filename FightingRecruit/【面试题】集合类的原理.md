###**ArrayList实现原理**

####**1.基本原理**

ArrayList是基于数组实现的，是一个动态数组，其容量能自动增长，允许重复，默认第一次插入元素时创建数组的大小为10，超出限制时会增加50%的容量，

####**2.扩容机制**

首先将容量扩展为原来的1.5倍，然后将新的容量与最大存储容量（Integer.MAX_VALUE - 8）比较，若大于最大存储容量，则取新的容量为整数最大值。

每次扩容底层采用System.arrayCopy()方法（native，浅拷贝）复制到新的数组，所以在初始化时最好能给出数组大小的预估值。

####**3.clone方法**

ArrayList的clone方法是深拷贝，而Object的clone方法是浅拷贝。

####**4.线程安全性**

ArrayList是线程不安全的，多线程环境下可以考虑用Collections.synchronizedList，或使用concurrent并发包下的CopyOnWriteArrayList类。虽然Vector是线程安全的，但是Vector是一个较老的集合，具有很多缺点，不建议使用

###**LinkedList实现原理**

####**1.基本原理**

LinkedList底层是基于双向链表实现的，但在JDK6之前却是基于循环链表实现的。LinkedList插入和删除操作更加高效，但随机访问速度慢；LinkedList支持null元素、有顺序、元素可以重复，LinkedList可以作为栈、队列、双端队列数据结构使用；

####**2.spliterator方法**

Spliterator可以理解为Iterator的Split版本（但用途要丰富很多）。使用Iterator的时候，我们可以顺序地遍历容器中的元素，使用Spliterator的时候，我们可以将元素分割成多份，分别交于不于的线程去遍历，以提高效率。使用 Spliterator 每次可以处理某个元素集合中的一个元素 , 不是从 Spliterator 中获取元素，而是使用 tryAdvance() 或 forEachRemaining() 方法对元素应用操作。但Spliterator 还可以用于估计其中保存的元素数量，而且还可以像细胞分裂一样变为一分为二。这些新增加的能力让流并行处理代码可以很方便地将工作分布到多个可用线程上完成。

###**HashMap的实现原理**

####**1.基本原理**

HashMap根据键的hashCode值存储数据，在JDK7中采用的是数组+链表的方式，而在JDK8中采用的是位桶+链表/红黑树的方式，当链表的长度大于8时，就将链表转换成红黑树， Node是HashMap的一个内部类，实现了Map.Entry接口，本质是就是一个映射(键值对)，Node[] table，即哈希桶数组，

####**2.确定哈希桶数组索引位置**

不管增加、删除、查找键值对，都要先定位到哈希桶数组的位置，HashMap的Hash算法本质上是三步：取key的hashCode值、高位运算（高16位异或低16位）、取模运算。

####**3.put方法**

首先判断数组table是否为空或长度为0，若是就执行resize()进行扩容，否则根据key计算hash值得到插入的数组索引i，若i桶为空，就新建节点添加，否则判断i桶的首个元素和key是否一样，若相同（hashcode与equals），就覆盖value，否则去判断是否为红黑树，若是就直接插入，否则遍历i桶，若链表长度大于8，就将链表转换为红黑树后插入，否则就在链表中插入，遍历i桶的过程中若发现key已经存在直接覆盖value即可。最后判断size是否超过threshold，如果超过，进行扩容。

####**4.扩容机制**

扩容(resize)就是重新计算容量，用一个新的数组代替已有的容量小的数组，若容量大于16（默认），就进行扩容，将size扩大为原来的2倍，然后重新确定索引值（rehash），在JDK1.7中需要重新计算hash，但在JDK8中只需要看原来的hash值新增的那个bit是1还是0，若是0索引不变，是1的话索引变成“原索引+oldCap”，若新表的数组索引位置相同，在JDK7中链表元素会倒置，但JDK8不会倒置。


####**5.get方法**

先通过计算key的hash值，找到哈希桶的位置，否则返回null，然后与桶的第一个key比较，若相同就返回，否则遍历红黑树查找，若没找到就在链表中查找key。HashMap使用链地址法来解决碰撞问题，当发生碰撞了，对象将会储存在链表的下一个节点中。 HashMap在每个链表节点中储存键值对对象。在JDK7中，若两个不同的键对象的hashcode相同， 即存储在同一个bucket位置的链表中。利用keys.equals()方法用来找到键值对。

####**6.线程安全性**

* 当HashMap在多线程的情况下同时put，若同时触发了rehash操作，会导致HashMap中的链表中出现循环节点（Node的next不为空），导致CPU利用率接近100%

* 解决方法：使用Collections.synchronizedMap或ConcurrentHashMap来保证线程安全。

* 利用负载因子，可以减缓哈希冲突，

###**ConcurrentHashMap实现原理**

####**1.基本原理**

* ConcurrentHashMap与HashMap类似，基于数组+链表/红黑树，但是为了实现并发，链表/红黑树增加了很多辅助的类，例如TreeBin，Traverser等对象内部类。相比于HashTable（只有一个锁），ConcurrentHashMap使用了分段锁，当一个线程占用锁访问其中一段数据的时候，其他段的数据也能被其他线程访问。这样就很高效了。

* jdk7针对ConcurrentHashMap的改进是增加了分段锁Segment对HashEntry的控制，其中，Segment继承ReentrantLock用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶。HashEntry 用来封装映射表的键 / 值对；每个桶是由若干个 HashEntry 对象链接起来的链表

* 在JDK8中，抛弃了Segment分段锁机制，利用Node + CAS + Synchronized机制来保证并发更新的安全，是低粒度加锁方式

* Node 是一个链表的结构，其中value和next都用volatile修饰，保证并发的可见性，而key和hash是final的。

####**2.初始化**

* 属性sizeCtl 默认为0，用来控制table的初始化和扩容操作，若sizeCtl=-1，表示正在初始化，-N 表示有N-1个线程正在进行扩容操作，正数或0表示还没有被初始化

* 关键字transient volatile 修饰的sizeCtl 和 Node数组table，它的初始化操作会延缓到第一次put行为，默认大小为16的数组，用来存储Node节点数据，扩容时大小总是2的幂次方。初始化时sizeCtl默认为0，如果ConcurrentHashMap实例化时有传参数，sizeCtl会是一个2的幂次方的值。所以执行第一次put操作的线程会执行Unsafe.compareAndSwapInt方法修改sizeCtl为-1，有且只有一个线程能够修改成功，其它线程通过Thread.yield()让出CPU时间片等待table初始化完成

####**3.put方法**

* 先获取键的hashCode值，再进行hash算法的计算得到hash值，找出索引位置，然后直接获取指定内存中table对应索引的元素f，若f为null，说明table中这个位置第一次插入元素，利用CAS方式插入Node节点，若插入成功，则会判断是否需要扩容，若插入失败，自旋重新尝试在这个位置插入节点。

* 若f的hash值为-1，表明有其它线程正在扩容，则帮助其进行扩容操作。其它情况把新的Node节点按链表或红黑树的方式插入到合适的位置，该过程采用同步内置锁f实现并发。

* 若该链表的数量大于阈值8，就要先转换成红黑树的结构，break再一次进入循环，如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容

####**4.扩容机制**

* 当table容量不足的时候，即table的元素数量达到容量阈值sizeCtl，需要对table进行扩容。先构建一个nextTable，大小为table的两倍。再把table的数据复制到nextTable中。

* 通过Unsafe.compareAndSwapInt修改sizeCtl值，保证只有一个线程能够初始化nextTable，扩容后的数组长度为原来的两倍，但是容量是原来的1.5。

* 节点从table移动到nextTable，是遍历、复制的过程。然后再把table指向nextTable，并更新sizeCtl为新数组大小的0.75倍 ，扩容完成。

####**5.红黑树构造**

* 如果链表结构中元素超过TREEIFY_THRESHOLD阈值，默认为8个，则把链表转化为红黑树，提高遍历查询效率

* 生成树节点的代码块是同步的，进入同步代码块之后，再次验证table中index位置元素是否被修改过。主要根据Node节点的hash值大小构建二叉树

####**6.get方法**

* 判断table是否为空，如果为空，直接返回null。

* 计算key的hash值，并获取指定table中指定位置的Node节点，通过遍历链表或则树结构找到对应的节点，返回value值。

####**7.remove操作**

* 若key为空，报NPE，首先计算根据key的hashCode计算hash值，得到位置i，若该桶的第一个元素为空或长度为0，就跳过，否则就进入同步代码块中，找到待删除节点的位置i后

* 把待删除节点之后的所有节点原样保留在新链表中，把待删除节点之前的每个节点克隆到新链表中，并指向当前删除节点的后面节点，（新链表的顺序被反转）


####**8.与HashTable的区别？**

* ConcurrentHashMap 是一个并发散列映射表的实现，它允许完全并发的读取，并且支持给定数量的并发更新。

* 而 HashTable 和Collections.synchronizedMap，HashTable是一个线程安全的类，它使用synchronized来锁住整张Hash表来实现线程安全，即每次锁住整张表让线程独占，同一时间点，只能有一个线程持有锁，这虽然保证多线程间的安全并发访问，但同时也导致对容器的访问变成串行化的了。

<br>
<br>
本人才疏学浅，若有错，请指出，谢谢！ 
如果你有更好的建议，可以留言我们一起讨论，共同进步！ 
衷心的感谢您能耐心的读完本篇博文！
