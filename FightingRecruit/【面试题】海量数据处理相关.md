###**海量数据处理思路**

* 针对时间，可以采用巧妙的算法搭配合适的数据结构，如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie/，

* 针对空间，无非就一个办法：大而化小：分而治之/hash映射，

* 处理海量数据的几种方法
 * 分而治之/hash映射 + hash统计 + 堆/快速/归并排序；
 * 双层桶划分；
 * Bloom filter/Bitmap；
 * Trie树/数据库/倒排索引；
 * 外排序；
 * 分布式处理之hadoop/mapreduce。
 * simhash 算法；
 * 布隆过滤器；

**Trie 树**

* Trie树，即字典树，又称单词查找树或键树，是一种树形结构。

* 典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是最大限度地减少无谓的字符串比较，查询效率比较高。

* Trie 的核心思想是空间换时间，利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的。

* Trie 的3 个基本性质
 * 根节点不包含字符，除根节点外每一个节点都只包含一个字符。
 * 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。
 *  每个节点的所有子节点包含的字符都不相同。


* 倒排索引（(Inverted index)）是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射，常被应用于搜索引擎和关键字查询的问题中。

###**海量数据处理实例**

**1.海量日志数据，提取出某日访问百度次数最多的那个IP**

* 算法思想：分而治之+Hash+排序

* 具体实现：先按照IP地址的Hash(IP)%1024值，把海量IP日志分别存储到1024个小文件中。这样，每个小文件最多包含4MB个IP地址，然后对于每一个小文件，可以构建一个IP为key，出现次数为value的Hash map，同时记录当前出现次数最多的那个IP地址；可得到1024个小文件中的出现次数最多的IP，最后依据常规的排序算法得到总体上出现次数最多的IP

**2.搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节，统计最热门的10个查询串，要求使用的内存不能超过1G。**

* 算法思想：hash映射+hash统计+排序

* 具体实现：先对这批海量数据预处理，存入hashmap(Query，Value)，Query表示字符串，而Value表示该Query出现次数的HashTable，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可，最终用Hash表完成了统计，O（n），最后进行堆/归并排序。

**3.一个文本文件，大约有一万行，每行一个词，要求统计出其中出现次数最频繁的10 个词**

* 算法思想：利用trie树

* 具体实现：用trie 树统计每个词出现的次数，时间复杂度是O(n  le)（le 表示单词的平均长度），然后是找出出现最频繁的前10 个词。当然，也可以用堆来实现，时间复杂度是O(n lg10)。总的时间复杂度，是O(nle)与O(nlg10)中较大的一个。


> 参考链接：[十道面试题与十个海量数据处理方法总结](http://blog.csdn.net/v_JULY_v/article/details/6279498)

未完待续.......

